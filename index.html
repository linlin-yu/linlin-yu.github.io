<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Linlin Yu | PhD @ UTD</title>

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/panda5.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Linlin Yu</name>
              </p>
              <p>I am a Ph.D. student in the Computer Science Department at <a href="https://www.utdallas.edu/">The University of Texas at Dallas</a>, 
                working under the supervision of <a href="https://personal.utdallas.edu/~fxc190007/">Prof. Feng Chen</a>. I also work closely with 
                <a href="https://sites.google.com/site/louyifei/">Prof. Yifei Lou</a>.
                I received my B.E. degree 
                in Information Security from <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a> in 2019. 
              </p>
              <p>
                My research focuses on evidential uncertainty quantification and reasoning for complex structural data. 
                I aim to improve the reliability of uncertainty estimations by integrating domain-specific prior knowledge. 
                My work has applications in areas such as attributed graphs, hyperspectral imaging (HSI) classification, bird's-eye view semantic segmentation (BEVSS), and generative models. 
              </p>
              <p>
                I am actively seeking research opportunities, including <strong>internships</strong> or <strong>full-time</strong> positions, in areas related to Deep Learning, Machine Learning, and Data Mining.  
                I'd love to get in contact.
              </p>

<!--               <font color="red"><strong>Seeking for full-time position in America starting from 2022</strong></font>  -->
              <p style="text-align:center">
                <a href="mailto:linlin.yu@utdallas.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=3pu55HoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/linlin-yu-723884249/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/linlin-yu">Github</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/person_1.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/person_1.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Quote</heading>
              <p>
                "<i> The fear of the LORD is the beginning of wisdom </i> " - Psalms 111:10
              </p>
            </td>
          </tr>
        </tbody></table> -->
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p></p>
                <li>01/2025: one paper got accepted by <strong>ICLR 2025</strong></li>
                <li>01/2025: one paper got accepted by <strong>AISTATS 2025</strong></li>
                <li>10/2024: one paper got accepted by <strong>Frontiers in BigData 2024</strong></li>
                <li>10/2024: I will serve as the reviewer of <strong>ICLR,AISTATS 2025</strong></li>
                <li>09/2024: one paper got accepted by <strong>EMNLP 2024</strong></li>
                <li>07/2024: I will serve as the reviewer of <strong>KDD 2025, BigData 2024</strong></li>
                <li>05/2024: I will give a talk on "Evidential Deep Learning for Uncertainty Quantification " in Tianjin University</li>
                <li>05/2024: We release the code and dataset for the first benchmark on uncertainty-aware bird's eye view segmentation</li>
                <li>05/2024: I will serve as the reviewer of <strong>NeurIPS 2024</strong></li>
                <li>03/2024: one paper got accepted by <strong>NAACL 2024 Finidings</strong></li>
                <li>01/2024: one paper got accepted by <strong>ICLR 2024 </strong></li>
                <li>09/2023: one paper got accepted by <strong>NeurIPS 2023 </strong></li>
                <li>06/2023: one paper got accepted by 2nd <strong>KDD workshop</strong> on Uncertainty Reasoning and Quantification in Decision Making</li>
              </p>
              </p>
            </td>
          </tr>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experience</heading>
              <p>
                <li>Reseracher</b> at NEC Laboratories America (Princeton, NJ) since 2022 summer</li>
                <li>Reserach intern</b> at NEC Laboratories America (Princeton, NJ) during 2021 summer</li>
                <li>Reserach intern</b> at Alibaba Damo Academy (Seattle, WA) during 2019 summer</li>
              </p>
              </p>
            </td>
          </tr>
        </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in machine learning and data mining, especially in Uncertainty Estimation, Trustworthy Large Language Models, and Graph Neural Networks.
                Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="Preprint2024_stop()" onmouseover="EMNLP2024_start()", bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='Preprint2024_image'>
                  <img src='images/Preprint2024_after.png' width="160"></div>
                <img src='images/Preprint2024_before.png' width="160">
              </div>
              <script type="text/javascript">
                function Preprint2024_start() {
                  document.getElementById('Preprint2024_image').style.opacity = "1";
                }

                function Preprint20244_stop() {
                  document.getElementById('Preprint2024_image').style.opacity = "0";
                }
                Preprint2024_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2405.20986">
                <papertitle>Uncertainty Quantification for Bird's Eye View Semantic Segmentation: Methods and Benchmarks</papertitle>
              </a>
              <br>
              <strong>Linlin Yu</strong>, Bowen Yang, Tianhao Wang, Kangshuo Li, Feng Chen
              <br>
              <em>Preprint</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2405.20986">paper</a> /
              <!-- <a href="https://github.com/he159ok/Benchmark-of-Uncertainty-Estimation-Methods-in-Text-Summarization">code</a> / -->
              <p></p>
              <p> This study investigates the uncertainty-aware Bird's Eye View(BEV) Semantic Segmentation task, which involves pixel-level classification
                in the BEV view while estimating the associated uncertainties. We propose a called UFCE loss, which is theoretically demonstrated can implicitly regularize
                sample weights, mitigating both under-fitting and over-fitting</p>
            </td>
          </tr>

          <tr onmouseout="EMNLP2024_stop()" onmouseover="FRONTIERS2024_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='EMNLP2024_image'>
                  <img src='images/EMNLP2024_after.png' width="160"></div>
                <img src='images/EMNLP2024_before.png' width="160">
              </div>
              <script type="text/javascript">
                function EMNLP2024_start() {
                  document.getElementById('EMNLP2024_image').style.opacity = "1";
                }

                function EMNLP2024_stop() {
                  document.getElementById('EMNLP2024_image').style.opacity = "0";
                }
                EMNLP2024_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2406.17274">
                <papertitle>Can We Trust the Performance Evaluation of Uncertainty Estimation
                  Methods in Text Summarization?</papertitle>
              </a>
              <br>
              Jianfeng He, Runing Yang, <strong>Linlin Yu</strong>, Changbin Li, Ruoxi Jia, Feng Chen, Ming Jin, Chang-Tien Lu
              <br>
              <em>EMNLP</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2406.17274">paper</a> /
              <a href="https://github.com/he159ok/Benchmark-of-Uncertainty-Estimation-Methods-in-Text-Summarization">code</a> /
              <p></p>
              <p> In this paper, we introduce a comprehensive uncertainty estimation on text summarization benchmark incorporating 31 NLG metrics across four dimensionse. We also assess the performance of 14 common uncertainty estimation methods within this benchmark.</p>
            </td>
          </tr>




          
            <tr onmouseout="FRONTIERS2024_stop()" onmouseover="NAACL2024_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='FRONTIERS2024_image'>
                  <img src='images/FRONTIERS2024_after.png' width="160"></div>
                <img src='images/FRONTIERS2024_before.png' width="160">
              </div>
              <script type="text/javascript">
                function FRONTIERS2024_start() {
                  document.getElementById('FRONTIERS2024_image').style.opacity = "1";
                }

                function FRONTIERS2024_stop() {
                  document.getElementById('FRONTIERS2024_image').style.opacity = "0";
                }
                FRONTIERS2024_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ijcai.org/proceedings/2024/0504.pdf">
              <a  <papertitle>Camera-view Supervision for Bird's-Eye-View Semantic Segmentation</papertitle>
              </a>
              <br>
              Bowen Yang, <strong>Linlin Yu</strong>, Feng Chen
              <br>
              <em>Frontiers in BigData</em>, 2024
              <br>
              <!-- <a href="https://www.ijcai.org/proceedings/2024/0504.pdf">paper</a> / -->
              <a href="https://github.com/bluffish/sucam">code</a> 
              <p></p>
              <p>  In this work, we introduce two novel supervision processes that significantly enhance the performance of real-time BEV semantic segmentation:
                camera-view depth supervision and camera-view segmentation supervision. </p>
            </td>
          </tr>

    
          <tr onmouseout="NAACL2024_stop()" onmouseover="ICLR2024_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='NAACL2024_image'>
                  <img src='images/NAACL2024_after.png' width="160"></div>
                <img src='images/NAACL2024_before.png' width="160">
              </div>
              <script type="text/javascript">
                function NAACL2024_start() {
                  document.getElementById('NAACL2024_image').style.opacity = "1";
                }

                function NAACL2024_stop() {
                  document.getElementById('NAACL2024_image').style.opacity = "0";
                }
                NAACL2024_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2311.08726">
                <papertitle>Uncertainty Estimation on Sequential Labeling via Uncertainty Transmission</papertitle>
              </a>
              <br>
              Jianfeng He, <strong>Linlin Yu</strong>,Shuo Lei, Chang-Tien Lu, Feng Chen
              <br>
              <em>NAACL Findings</em>, 2024 
              <br>
              <a href="https://arxiv.org/abs/2311.08726">paper</a> /
              <a href="https://github.com/he159ok/UncSeqLabeling_SLPN">code</a> /
              <p></p>
              <p> We propose a Sequential Labeling Posterior Network (SLPN) to estimate uncertainty scores for the extracted entities, considering uncertainty transmitted from other tokens. Moreover, we have defined an evaluation strategy to address the specificity of wrong-span cases. </p>
            </td>
          </tr>


          <tr onmouseout="ICLR2024_stop()" onmouseover="NIPS2024_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ICLR2024_image'>
                  <img src='images/ICLR2024_after.png' width="160"></div>
                <img src='images/ICLR2024_after.png' width="160">
              </div>
              <script type="text/javascript">
                function ICLR2024_start() {
                  document.getElementById('ICLR2024_image').style.opacity = "1";
                }

                function ICLR2024_stop() {
                  document.getElementById('ICLR2024_image').style.opacity = "0";
                }
                ICLR2024_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/pdf?id=8dN7gApKm3">
                <papertitle>Uncertainty-aware Graph-based Hyperspectral Image Classification</papertitle>
              </a>
              <br>
              <strong>Linlin Yu</strong>,
              <a href="https://sites.google.com/site/louyifei/">Yifei Lou</a>,
              <a href="https://personal.utdallas.edu/~fxc190007/">Feng Chen</a>,
              <br>
              <em>ICLR</em>, 2024 
              <!-- <em>NeurIPS</em>, 2020 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>  -->
              <br>
              <a href="https://openreview.net/pdf?id=8dN7gApKm3">paper</a> /
              <a href="https://github.com/linlin-yu/uncertainty-aware-HSIC.git">code</a> /
              <a href="https://iclr.cc/media/PosterPDFs/ICLR%202024/19322.png?t=1714868237.0518255">poster</a> /
              <p></p>
              <p>We propose a graph-based uncertainty quantification framework for hyper spectral imaging classification that is novel in deep
                learning and hyperspectral literature. We point out scenarios when UCE cannot separate ID and
                OOD nodes. To mitigate the limitation, we leverage inherent physical characteristics of HS data
                and edge-preserving regularization to propagate evidence in the spatial domain.</p>
            </td>
          </tr> 

          <tr onmouseout="NeurIPS2024_stop()" onmouseover="NeurIPS2024_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='NeurIPS2024_image'>
                  <img src='images/NeurIPS2024_after.png' width="160"></div>
                <img src='images/NeurIPS2024_before.png' width="160">
              </div>
              <script type="text/javascript">
                function NeurIPS2024_start() {
                  document.getElementById('NeurIPS2024_image').style.opacity = "1";
                }

                function NeurIPS2024_stop() {
                  document.getElementById('NeurIPS2024_image').style.opacity = "0";
                }
                NeurIPS2024_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/ad84864002a72c344c2227d7eb8842b1-Paper-Conference.pdf">
                <papertitle>Improvements on Uncertainty Quantification for Node Classification via Distance Based Regularization</papertitle>
              </a>
              <br>
              Russell Hart,
              <strong>Linlin Yu</strong>,
              <a href="https://sites.google.com/site/louyifei/">Yifei Lou</a>,
              <a href="https://personal.utdallas.edu/~fxc190007/">Feng Chen</a>,
              <br>
              <em>NeurIPS</em>, 2024 
              <!-- <em>NeurIPS</em>, 2020 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>  -->
              <br>
              <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/ad84864002a72c344c2227d7eb8842b1-Paper-Conference.pdf">paper</a> /
              <a href="https://github.com/neoques/Graph-Posterior-Network">code</a> /
              <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202023/71909.png?t=1702266175.3741667">poster</a> /
              <p></p>
              <p>We theoretically analyze the limitations of GPN at OOD detection when minimizing uncertainty cross-entropy loss, and we propose a
                distance-based regularization that considers the prior knowledge that OOD-specific features are useful
                for learning representational space mappings.</p>
            </td>
          </tr> 

        </tbody></table>



  
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/NIPS_logo.png" width="180"></td> -->
            <td width="75%" valign="center">
              <b>Conference Reviewer</b>
              <li>ICLR 2025, KDD 2025, AISTATS 2025</li>
              <li>KDD 2024, NeurIPS 2024, BigData 2024, ICML 2024</li>
              <li>ICML 2023 </li>
            </td>
          </tr>
          <tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody><tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info/">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
